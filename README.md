# Документация

## Описание классов

---

### AMyAIVehicle

Класс описывает параметры и методы для восприятия окружающей среды.


####  **Параметры**
*FVector* **FCollisionBoxSize** - Вектор, определяющий размер коробки, которая вписывает машину. По умолчанию {230, 110, 74}.

*float* **LineTraceLengthByForward** -Длина луча при трасировке. По умолчанию 2200.

*bool* **bDebug** - Параметр, определяющий, показывать ли лучи. По умолчанию true.

*TArray<ATargetPoint\*>* **ATargetPointList** - Список точек, к которым нужно проехать.
 
---

####  Методы

**AMyAIVehicle**()

*void** **GetLineTraceForward**(*bool* **&bHit**, *FVector* **&FNeedLocation**) - Выпускает вперед луч, дальностью **LineTraceLengthByForward**. **bHit** равен true, если было столкновение. Так же, если было столкновение, то попробует выпустить более короткий луч, зеркальный предыдущему. Если в этот раз не было столкновения **FNeedLocation** становится равен зеркальной точки излучения по нормали от первого столкновения, если было, то зеркальной точке первого стокновения от второго по нормали второго стокновения.

*ATargetPoint\** **GetNewTargetPoint**() - Возвращает указатель на новую позицию, которую нужно посетить. Если нет такой, возвращает нулевой указатель.

---

### AMyAIController

Класс описывает методы для использования данных об окружающей среде и обеспечивает связь между транспортным средством, behaviorTree и нейронной сетью. 

#### Параметры


*bool* **TurnRight** - Логическая переменная, показывающая, производиться ли поворот направо. На старте *false*.

*bool* **TurnLeft** - Логическая переменная, показывающая, производиться ли поворот налево. На старте *false*.

*FVector* **NeedLocation** - Вектор, показывающий подпункт для посещения.

*ATargetPoint\** **ACurrentTargetPoint** - текущая точка для посещения.

*float* **AcceptableRadius** - расстояние между машиной и **ACurrentTargetPoint**, при котором считается, что **ACurrentTargetPoint** был достигнут. По умолчанию 100.f.


#### Методы

*void* **SetVehicleMovement**(*float* **ThrottleInput**, *float* **SteeringInput**, *bool* **HandbrakeInput**) - Устанавливает скорость **ThrottleInput**, поворот **SteeringInput**, и ручник **HandbrakeInput**.

*void* **Tick**(*float* **Delta**) - Вызывается каждый кадр. Если **TurnLeft** или **TurnRight** равен *true*, то поворачивает только в налево или направо соответственно, пока не будет достигнут подпункт **NeedLocation**. Может обновить **NeedLocation**, если он окажется левее или правее соответственно. Если же **TurnLeft** и **TurnRight** равны *false*, то старается повернуть в сторону **ACurrentTargetPoint**.


## Резюме

Собственно, сам алгоритм прост. И неоптимален. Мне кажется что алгоритм "Посмотри вокруг, обернись назад, а затем реши куда куда повернуть", а это есть ничто другое, как жадный алгоритм, вряд ли покажет себя очень хорошо. Может если использовать в купе с навмешем. Насколько я помню, из него можно получить сам маршрут, имеющий точки в поворотах. Вот если использовать эти точки с этим алгоритмом, или его улучшенной версией, то может быть. К примеру, одна из ахиллесовых пят алгоритма, это если есть таргет ровно впереди, а чуток за ним стена. Происходит примерно "Наша цель впереди, полный вперед. О нет, там стена, полный разворот.
А касательно моего старого предложения, с нейронками, то я не считаю, что нейронные сети такие уж избыточны в данном вопросе. Может быть не вполне корректен. К примеру, если глянуть что я передаю в **SetVehicleMovement**, то там корень берется из числа. В какой-то момент я понял, что строго "направо, налево, вперед", ну это не так уж и хорошо, может произойти резкое передергивание. Поэтому 3 варинта действия стоит повысить хотябы до 5, чтоб было "Направо, чуток направо, вперед, чуток налево, налево". Плюс, ради избежания ошибки с таргетом у стены, можно передавать число, показывающая, как близко находится машина к цели. К примеру, минимум от условных 3 метров и расстояния до таргета, деленые на те самые 3 метра. Плюс, оно будет как-то более грамотно использовать данные. Я уверен, что можно все расчитать, и сказать как кататься машине относительно полученных данных с трасировки, но тот алгоритм, он по идее, должен привыкнуть к своим параметрам. Грубо говоря он должен будет понять "Да, слева стена, но она на безопасном расстоянии и мне не нужно панически сворачивать направо, придерживаемся курса".
